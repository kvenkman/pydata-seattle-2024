{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1f80dcff",
   "metadata": {},
   "source": [
    "## Retrieving OPERA disturbance data\n",
    "\n",
    "The [OPERA DIST-HLS data product](https://lpdaac.usgs.gov/documents/1766/OPERA_DIST_HLS_Product_Specification_V1.pdf) can be used to study vegetation disturbances over time. In this notebook, we will retrieve disturbance data \n",
    "over\n",
    "associated with the [2023 Greece wildfires](https://en.wikipedia.org/wiki/2023_Greece_wildfires) to understand its evolution and extent. We will also generate a time series visualization of the event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7f1cede",
   "metadata": {},
   "outputs": [],
   "source": [
    "import rasterio\n",
    "import rioxarray\n",
    "import hvplot.pandas  # noqa\n",
    "import hvplot.xarray  # noqa\n",
    "from rasterio.warp import transform_bounds, reproject\n",
    "from rasterio.crs import CRS\n",
    "import contextily as cx\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import xarray as xr\n",
    "import xyzservices.providers as xyz\n",
    "\n",
    "from shapely.geometry import Point\n",
    "from osgeo import gdal\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Imports for plotting\n",
    "import geoviews as gv\n",
    "gv.extension('bokeh')\n",
    "gv.output(size=1000)\n",
    "\n",
    "# STAC imports to retrieve cloud data\n",
    "from pystac_client import Client\n",
    "\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "\n",
    "# GDAL setup for accessing cloud data\n",
    "gdal.SetConfigOption('GDAL_HTTP_COOKIEFILE','~/cookies.txt')\n",
    "gdal.SetConfigOption('GDAL_HTTP_COOKIEJAR', '~/cookies.txt')\n",
    "gdal.SetConfigOption('GDAL_DISABLE_READDIR_ON_OPEN','EMPTY_DIR')\n",
    "gdal.SetConfigOption('CPL_VSIL_CURL_ALLOWED_EXTENSIONS','TIF, TIFF')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f852875f",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Let's set up the parameters of our search query\n",
    "\n",
    "# Flooding in Texas, 2024; \n",
    "wadi_sirhan_basin = Point(16.5, -16.09).buffer(0.01)\n",
    "\n",
    "# We will search data around the flooding event at the start of May\n",
    "start_date = datetime(year=2023, month=1, day=1)\n",
    "stop_date = datetime(year=2024, month=6, day=1)\n",
    "date_range = f'{start_date.strftime(\"%Y-%m-%d\")}/{stop_date.strftime(\"%Y-%m-%d\")}'\n",
    "\n",
    "# We open a client instance to search for data, and retrieve relevant data records\n",
    "STAC_URL = 'https://cmr.earthdata.nasa.gov/stac'\n",
    "\n",
    "# Setup PySTAC client\n",
    "# LPCLOUD refers to the LP DAAC cloud environment that hosts OPERA DIST data\n",
    "\n",
    "catalog = Client.open(f'{STAC_URL}/LPCLOUD/')\n",
    "collections = [\"OPERA_L3_DIST-ALERT-HLS_V1\"]\n",
    "\n",
    "opts = {\n",
    "    'bbox' : wadi_sirhan_basin.bounds, \n",
    "    'collections': collections,\n",
    "    'datetime' : date_range,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e54f8bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute the search\n",
    "search = catalog.search(**opts)\n",
    "results = list(search.items_as_dicts())\n",
    "print(f\"Number of tiles found intersecting given AOI: {len(results)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f73533dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_name = 'VEG-DIST-STATUS'\n",
    "\n",
    "times = pd.DatetimeIndex([result['properties']['datetime'] for result in results]) # parse of timestamp for each result\n",
    "data = {'hrefs': [value['href'] for result in results for key, value in result['assets'].items() if layer_name in key],  # parse out links only to DIST-STATUS data layer\n",
    "        'tile_id': [value['href'].split('/')[-1].split('_')[3] for result in results for key, value in result['assets'].items() if layer_name in key]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "295e3301",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Construct pandas dataframe to summarize granules from search results\n",
    "granules = pd.DataFrame(index=times, data=data)\n",
    "granules.index.name = 'times'\n",
    "granules.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9123051d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_granules = granules[:10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0d15a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(test_granules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50e1f2b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def urls_to_dataset(granule_dataframe):\n",
    "    '''method that takes in a list of OPERA tile URLs and returns an xarray dataset with dimensions\n",
    "    latitude, longitude and time'''\n",
    "\n",
    "    dataset_list = []\n",
    "    \n",
    "    for i, row in granule_dataframe.iterrows():\n",
    "        with rasterio.open(row.hrefs) as ds:\n",
    "            # extract CRS string\n",
    "            crs = str(ds.crs).split(':')[-1]\n",
    "\n",
    "            # extract the image spatial extent (xmin, ymin, xmax, ymax)\n",
    "            xmin, ymin, xmax, ymax = ds.bounds\n",
    "\n",
    "            # the x and y resolution of the image is available in image metadata\n",
    "            x_res = np.abs(ds.transform[0])\n",
    "            y_res = np.abs(ds.transform[4])\n",
    "\n",
    "            # read the data \n",
    "            img = ds.read()\n",
    "\n",
    "            # Ensure img has three dimensions (bands, y, x)\n",
    "            if img.ndim == 2:\n",
    "                img = np.expand_dims(img, axis=0) \n",
    "\n",
    "            \n",
    "\n",
    "        lon = np.arange(xmin, xmax, x_res)\n",
    "        lat = np.arange(ymax, ymin, -y_res)\n",
    "\n",
    "        lon_grid, lat_grid = np.meshgrid(lon, lat)\n",
    "\n",
    "        da = xr.DataArray(\n",
    "            data=img,\n",
    "            dims=[\"band\", \"y\", \"x\"],\n",
    "            coords=dict(\n",
    "                lon=([\"y\", \"x\"], lon_grid),\n",
    "                lat=([\"y\", \"x\"], lat_grid),\n",
    "                time=i,\n",
    "                band=np.arange(img.shape[0])\n",
    "            ),\n",
    "            attrs=dict(\n",
    "                description=\"OPERA DIST\",\n",
    "                units=None,\n",
    "            ),\n",
    "        )\n",
    "        da.rio.write_crs(crs, inplace=True)\n",
    "\n",
    "        dataset_list.append(da)\n",
    "    return xr.concat(dataset_list, dim='time').squeeze()\n",
    "\n",
    "dataset= urls_to_dataset(test_granules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf0da6ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "COLORS = [(0, 0, 0, 0)]*256 # Set cmap where all classes are zero opacity\n",
    "COLORS[1] = (255, 0, 0, 1)\n",
    "COLORS[2] = (255, 0, 0, 1)\n",
    "COLORS[4] = (255, 0, 0, 1) # We only visualize confirmed disturbances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "849739ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = dataset.hvplot.quadmesh(title = 'Crop circles in UAE',\n",
    "                            x='lon', y='lat', \n",
    "                            project=True, rasterize=True, frame_width=100,\n",
    "                            cmap=COLORS, \n",
    "                            colorbar=False,\n",
    "                            widget_location='bottom',\n",
    "                            tiles = xyz.OpenStreetMap.Mapnik,\n",
    "                            xlabel='Longitude (degrees)',ylabel='Latitude (degrees)',\n",
    "                            fontscale=1.25)\n",
    "\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b06967c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46b3fcee",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf = gpd.read_file('/home/karthik/Desktop/workspace/pydata-seattle-2024/data/landsat_ot_c2_l2_667298b52c41d8f6/landsat_ot_c2_l2_667298b52c41d8f6.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f825da43",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf.hvplot(geo=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20ce5c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_geometry = gdf['geometry'].unary_union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a7c3413",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_gdf = gpd.GeoDataFrame(data = {'merged_shape':[0]}, geometry=[final_geometry])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcef1b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "974a8733",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(10, 10))\n",
    "test_gdf.geometry.plot(ax=ax, facecolor=\"none\", edgecolor=\"red\", linewidth=1)\n",
    "cx.add_basemap(ax, crs=gdf.crs, zoom=1, source=cx.providers.OpenStreetMap.Mapnik, attribution='')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
